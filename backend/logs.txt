=> Running 'npm start'
> call-flow-weaver-backend@1.0.0 start
> node server.js
ðŸš€ Production mode: Using Render environment variables
[ConversationRelay-WS] ðŸš€ Twilio ConversationRelay WebSocket server initialized
[ConversationRelay-WS] ðŸŽ™ï¸  Using ConversationRelay built-in STT/TTS capabilities
[ConversationRelay-WS] ðŸ“¡ WebSocket server listening on path: /api/conversationrelay-ws
[ConversationRelay-WS] ðŸ”Š Ready to accept Twilio ConversationRelay connections
[ConversationRelay-WS] âœ… WebSocket server setup complete - waiting for Twilio connections...
ðŸŽ™ï¸  ConversationRelay WebSocket server initialized
ðŸ“¡ Real-time audio streaming: wss://kimiyi-ai.onrender.com/api/conversationrelay-ws
ðŸš€ Call Flow Weaver Backend running on port 10000
ðŸ“ž TwiML endpoints ready for Twilio webhooks
ðŸ”— Health check: http://localhost:10000/health
âš¡ Performance optimization system loaded
ðŸŽ¯ Expected response time: 150-250ms (92% faster than traditional)
ðŸ”¥ Optimized endpoints:
   â€¢ POST /api/make-call-optimized
   â€¢ POST /api/twiml-optimized
   â€¢ GET  /api/performance-metrics
   â€¢ GET  /api/health-optimized
[ConversationRelay-WS] ðŸ‘‚ WebSocket server is listening for connections
     ==> Your service is live ðŸŽ‰
     ==> 
     ==> ///////////////////////////////////////////////////////////
     ==> 
     ==> Available at your primary URL https://kimiyi-ai.onrender.com
     ==> 
     ==> ///////////////////////////////////////////////////////////
     ==> Detected service running on port 10000
     ==> Docs on specifying a port: https://render.com/docs/web-services#port-binding
=== OPTIMIZED MAKE CALL REQUEST ===
Timestamp: 2025-08-29T05:46:13.596Z
Request body keys: [
  'to',
  'from',
  'workflowId',
  'nodes',
  'edges',
  'globalPrompt',
  'config',
  'record',
  'timeout',
  'twilioAccountSid',
  'twilioAuthToken'
]
[PredictiveCache] Initialized with config: { maxCacheSize: 10000, maxAge: 86400000, semanticThreshold: 0.85 }
[LanguageOptimizer] Initialized with support for 53 languages
[LanguageOptimizer] Cantonese specialization enabled
[StreamingAudioProcessor] Initialized with config: {
  sampleRate: 8000,
  audioFormat: 'mulaw',
  streamingMode: 'bidirectional',
  optimizations: {
    noiseReduction: true,
    echoCancellation: true,
    voiceActivityDetection: true
  }
}
[StreamingAudioProcessor] Initialized with config: {
  sampleRate: 8000,
  audioFormat: 'mulaw',
  streamingMode: 'bidirectional',
  optimizations: {
    noiseReduction: true,
    echoCancellation: true,
    voiceActivityDetection: true
  }
}
[ConversationRelay] Initialized with bidirectional streaming
[PerformanceOrchestrator] Initialized with all optimizations enabled
[PerformanceOrchestrator] Starting optimized conversation for call call_1756446373596_5k7qrobzy
[ConversationRelay] Starting conversation for call call_1756446373596_5k7qrobzy
[ConversationRelay] Workflow data: {
  workflowId: 'workflow-1756446371886',
  nodesCount: 12,
  edgesCount: 16,
  hasGlobalPrompt: true
}
[ConversationRelay] WebSocket connection setup for call call_1756446373596_5k7qrobzy (using TwiML bridge)
[ConversationRelay] Audio pipeline configured
[ConversationRelay] Stream initialized for call call_1756446373596_5k7qrobzy
[ConversationRelay] Bidirectional streaming setup complete for call call_1756446373596_5k7qrobzy
[ConversationRelay] Conversation started in 34.1970390000497ms
[PerformanceOrchestrator] Optimized conversation started in 34.60634900000878ms
Performance optimization initialized: {
  success: true,
  callSid: 'call_1756446373596_5k7qrobzy',
  optimizations: {
    conversationRelay: true,
    predictiveCache: true,
    languageOptimization: true,
    providerFailover: true
  },
  expectedLatency: '150-250ms'
}
Using optimized TwiML endpoint: https://kimiyi-ai.onrender.com/api/twiml-optimized?id=workflow-1756446371886&trackingId=call_1756446373596_5k7qrobzy
Optimized Twilio API call parameters: {
  To: '+919649770017',
  From: '+17077433838',
  Url: 'https://kimiyi-ai.onrender.com/api/twiml-optimized?id=workflow-1756446371886&trackingId=call_1756446373596_5k7qrobzy',
  OptimizationEnabled: true,
  ExpectedLatency: '150-250ms',
  TrackingId: 'call_1756446373596_5k7qrobzy'
}
Twilio call created successfully: {
  callSid: 'CA04f88bc4f0a4c86be3ac9770036330dd',
  status: 'queued',
  to: '+919649770017',
  from: '+17077433838',
  optimizationEnabled: true,
  trackingId: 'call_1756446373596_5k7qrobzy'
}
[TwiML-Optimized] ===== FAST TWIML REQUEST =====
[TwiML-Optimized] Call: CA04f88bc4f0a4c86be3ac9770036330dd, Workflow: workflow-1756446371886, Tracking: call_1756446373596_5k7qrobzy
[generateFastTwiML] ===== CREATING TWIML =====
[generateFastTwiML] Workflow: workflow-1756446371886, Tracking: call_1756446373596_5k7qrobzy
[generateFastTwiML] WebSocket URL: wss://kimiyi-ai.onrender.com/api/conversationrelay-ws?workflowId=workflow-1756446371886&trackingId=call_1756446373596_5k7qrobzy
[generateFastTwiML] ===== TWIML GENERATED =====
[generateFastTwiML] TwiML length: 420 chars
[generateFastTwiML] WebSocket URL encoded: wss://kimiyi-ai.onrender.com/api/conversationrelay-ws?workflowId=workflow-1756446371886&amp;trackingId=call_1756446373596_5k7qrobzy
[generateFastTwiML] ACTUAL TWIML CONTENT:
<?xml version="1.0" encoding="UTF-8"?>
<Response>
    <Connect>
        <ConversationRelay
            url="wss://kimiyi-ai.onrender.com/api/conversationrelay-ws?workflowId=workflow-1756446371886&amp;trackingId=call_1756446373596_5k7qrobzy"
            welcomeGreeting="Hello Aditya! I'm your Kimiya. How can I help you today?"
            voice="alice"
            language="en-US"
        />
    </Connect>
</Response>
[TwiML-Optimized] FAST TwiML generated in 0.62ms
[TwiML-Optimized] Background orchestrator ready for call_1756446373596_5k7qrobzy
[Call Status Optimized] Call CA04f88bc4f0a4c86be3ac9770036330dd status: completed, tracking: call_1756446373596_5k7qrobzy
[PerformanceOrchestrator] Stopping optimized conversation for call CA04f88bc4f0a4c86be3ac9770036330dd
[ConversationRelay] Stopping conversation for call CA04f88bc4f0a4c86be3ac9770036330dd
[PerformanceOrchestrator] Failed to stop optimized conversation: Error: No call data found for CA04f88bc4f0a4c86be3ac9770036330dd
    at PerformanceOrchestrator.stopOptimizedConversation (/opt/render/project/src/backend/services/performanceOrchestrator.js:147:15)
    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)
    at async /opt/render/project/src/backend/routes/optimized-routes.js:50:11
[Call Status Optimized] Error cleaning up orchestrator: Error [ERR_UNHANDLED_ERROR]: Unhandled error. ({
  callSid: 'CA04f88bc4f0a4c86be3ac9770036330dd',
  error: Error: No call data found for CA04f88bc4f0a4c86be3ac9770036330dd
      at PerformanceOrchestrator.stopOptimizedConversation (/opt/render/project/src/backend/services/performanceOrchestrator.js:147:15)
      at process.processTicksAndRejections (node:internal/process/task_queues:105:5)
      at async /opt/render/project/src/backend/routes/optimized-routes.js:50:11,
  phase: 'cleanup'
})
    at PerformanceOrchestrator.emit (node:events:497:17)
    at PerformanceOrchestrator.stopOptimizedConversation (/opt/render/project/src/backend/services/performanceOrchestrator.js:159:12)
    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)
    at async /opt/render/project/src/backend/routes/optimized-routes.js:50:11 {
  code: 'ERR_UNHANDLED_ERROR',
  context: {
    callSid: 'CA04f88bc4f0a4c86be3ac9770036330dd',
    error: Error: No call data found for CA04f88bc4f0a4c86be3ac9770036330dd
        at PerformanceOrchestrator.stopOptimizedConversation (/opt/render/project/src/backend/services/performanceOrchestrator.js:147:15)
        at process.processTicksAndRejections (node:internal/process/task_queues:105:5)
        at async /opt/render/project/src/backend/routes/optimized-routes.js:50:11,
    phase: 'cleanup'
  }
}
[Optimized Route] POST /call-status-optimized - 200 - 3ms